{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_swf_file(file_path):\n",
    "    col_names = ['job_number', 'submit_time', 'wait_time', 'run_time', 'num_procs',\n",
    "                 'avg_cpu_time', 'used_memory', 'req_procs', 'req_time', 'req_memory',\n",
    "                 'status', 'user_id', 'group_id', 'exec_id', 'queue_id',\n",
    "                 'partition_id', 'orig_site', 'last_run_site']\n",
    "    df = pd.read_csv(file_path, comment=';', header=None, names=col_names, delim_whitespace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'LANL-CM5-1994-4.1-cln'\n",
    "\n",
    "file_path = \"../raw_data/\" + filename + \".swf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = ['wait_time', 'req_procs', 'req_memory', 'req_time', \n",
    "                    'active_jobs_count', 'total_used_procs', 'mean_used_procs', 'total_used_memory', 'mean_used_memory',\n",
    "                    'queued_jobs_count', 'mean_wait_time', 'max_wait_time', 'min_wait_time', 'mean_req_procs', 'max_req_procs', 'min_req_procs',\n",
    "                    'mean_req_time', 'max_req_time', 'min_req_time', 'mean_req_memory', 'max_req_memory', 'min_req_memory',\n",
    "                    'completed_jobs_count', 'mean_wait_time_completed', 'max_wait_time_completed', 'min_wait_time_completed',\n",
    "                    'mean_run_time_completed', 'max_run_time_completed', 'min_run_time_completed', 'mean_procs_completed',\n",
    "                    'max_procs_completed', 'min_procs_completed', 'mean_memory_completed', 'max_memory_completed', 'min_memory_completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, recent_interval=3600):\n",
    "    def get_queued_jobs_features(row, df, recent_interval=3600):\n",
    "        submit_time = row['submit_time']\n",
    "        \n",
    "        # Filter out the active and queued jobs\n",
    "        all_active_jobs = df[(df['submit_time'] <= submit_time) & (submit_time < df['submit_time'] + df['wait_time'] + df['run_time'])]\n",
    "        active_jobs = all_active_jobs[all_active_jobs['submit_time'] + all_active_jobs['wait_time'] <= submit_time]\n",
    "        queued_jobs = all_active_jobs[all_active_jobs['submit_time'] + all_active_jobs['wait_time'] > submit_time]\n",
    "        \n",
    "        # Calculate features for active jobs\n",
    "        row['active_jobs_count'] = len(active_jobs)\n",
    "        row['total_used_procs'] = active_jobs['num_procs'].sum()\n",
    "        row['mean_used_procs'] = active_jobs['num_procs'].mean()\n",
    "        row['total_used_memory'] = active_jobs['used_memory'].sum()\n",
    "        row['mean_used_memory'] = active_jobs['used_memory'].mean()\n",
    "\n",
    "        # Calculate features for queued jobs\n",
    "        row['queued_jobs_count'] = len(queued_jobs)\n",
    "        row['mean_wait_time'] = queued_jobs['wait_time'].mean()\n",
    "        row['max_wait_time'] = queued_jobs['wait_time'].max()\n",
    "        row['min_wait_time'] = queued_jobs['wait_time'].min()\n",
    "        row['mean_req_procs'] = queued_jobs['req_procs'].mean()\n",
    "        row['max_req_procs'] = queued_jobs['req_procs'].max()\n",
    "        row['min_req_procs'] = queued_jobs['req_procs'].min()\n",
    "        row['mean_req_time'] = queued_jobs['req_time'].mean()\n",
    "        row['max_req_time'] = queued_jobs['req_time'].max()\n",
    "        row['min_req_time'] = queued_jobs['req_time'].min()\n",
    "        row['mean_req_memory'] = queued_jobs['req_memory'].mean()\n",
    "        row['max_req_memory'] = queued_jobs['req_memory'].max()\n",
    "        row['min_req_memory'] = queued_jobs['req_memory'].min()\n",
    "\n",
    "        # Calculate features for recently completed jobs\n",
    "        recent_jobs = df[(df['submit_time'] + df['wait_time'] + df['run_time'] >= submit_time - recent_interval) &\n",
    "                         (df['submit_time'] + df['wait_time'] + df['run_time'] <= submit_time)]\n",
    "        row['completed_jobs_count'] = len(recent_jobs)\n",
    "        row['mean_wait_time_completed'] = recent_jobs['wait_time'].mean()\n",
    "        row['max_wait_time_completed'] = recent_jobs['wait_time'].max()\n",
    "        row['min_wait_time_completed'] = recent_jobs['wait_time'].min()\n",
    "        row['mean_run_time_completed'] = recent_jobs['run_time'].mean()\n",
    "        row['max_run_time_completed'] = recent_jobs['run_time'].max()\n",
    "        row['min_run_time_completed'] = recent_jobs['run_time'].min()\n",
    "        row['mean_procs_completed'] = recent_jobs['num_procs'].mean()\n",
    "        row['max_procs_completed'] = recent_jobs['num_procs'].max()\n",
    "        row['min_procs_completed'] = recent_jobs['num_procs'].min()\n",
    "        row['mean_memory_completed'] = recent_jobs['used_memory'].mean()\n",
    "        row['max_memory_completed'] = recent_jobs['used_memory'].max()\n",
    "        row['min_memory_completed'] = recent_jobs['used_memory'].min()\n",
    "\n",
    "        if pd.isna(row['req_procs']):\n",
    "            print('hello1')\n",
    "            row['req_procs'] = queued_jobs['req_procs'].median()\n",
    "        \n",
    "        if pd.isna(row['req_memory']):\n",
    "            print('hello1')\n",
    "            row['req_mem'] = queued_jobs['req_memory'].median()\n",
    "        \n",
    "        if pd.isna(row['req_time']):\n",
    "            print('hello3')\n",
    "            row['req_time'] = queued_jobs['req_time'].median()\n",
    "        \n",
    "        return row\n",
    "\n",
    "    df = df.progress_apply(lambda row: get_queued_jobs_features(row, df), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Смотри самую популярную очередь\n",
    "# df['queue_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 112/85329 [00:06<1:23:18, 17.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'min_memory_completed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/series.py:1105\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_with_engine(key, value)\n\u001b[1;32m   1106\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[39m# We have a scalar (or for MultiIndex or object-dtype, scalar-like)\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[39m#  key that is not present in self.index.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/series.py:1175\u001b[0m, in \u001b[0;36mSeries._set_with_engine\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_with_engine\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   1177\u001b[0m     \u001b[39m# this is equivalent to self._values[key] = value\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'min_memory_completed'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mqueue_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \n\u001b[1;32m      8\u001b[0m df\u001b[39m.\u001b[39mreplace(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m df_with_features \u001b[39m=\u001b[39m extract_features(df)\n\u001b[1;32m     10\u001b[0m dataset \u001b[39m=\u001b[39m df_with_features[dataset_features]\n\u001b[1;32m     12\u001b[0m df_with_features\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m../prepared_data/full_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m filename \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 63\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(df, recent_interval)\u001b[0m\n\u001b[1;32m     59\u001b[0m         row[\u001b[39m'\u001b[39m\u001b[39mreq_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m queued_jobs[\u001b[39m'\u001b[39m\u001b[39mreq_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmedian()\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m row\n\u001b[0;32m---> 63\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mprogress_apply(\u001b[39mlambda\u001b[39;49;00m row: get_queued_jobs_features(row, df), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    806\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[13], line 63\u001b[0m, in \u001b[0;36mextract_features.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     59\u001b[0m         row[\u001b[39m'\u001b[39m\u001b[39mreq_time\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m queued_jobs[\u001b[39m'\u001b[39m\u001b[39mreq_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmedian()\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m row\n\u001b[0;32m---> 63\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mprogress_apply(\u001b[39mlambda\u001b[39;00m row: get_queued_jobs_features(row, df), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m, in \u001b[0;36mextract_features.<locals>.get_queued_jobs_features\u001b[0;34m(row, df, recent_interval)\u001b[0m\n\u001b[1;32m     45\u001b[0m row[\u001b[39m'\u001b[39m\u001b[39mmean_memory_completed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m recent_jobs[\u001b[39m'\u001b[39m\u001b[39mused_memory\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     46\u001b[0m row[\u001b[39m'\u001b[39m\u001b[39mmax_memory_completed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m recent_jobs[\u001b[39m'\u001b[39m\u001b[39mused_memory\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\n\u001b[0;32m---> 47\u001b[0m row[\u001b[39m'\u001b[39m\u001b[39mmin_memory_completed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m recent_jobs[\u001b[39m'\u001b[39m\u001b[39mused_memory\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin()\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m pd\u001b[39m.\u001b[39misna(row[\u001b[39m'\u001b[39m\u001b[39mreq_procs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhello1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/series.py:1127\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_values(key, value)\n\u001b[1;32m   1125\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m         \u001b[39m# GH#12862 adding a new key to the Series\u001b[39;00m\n\u001b[0;32m-> 1127\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1129\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# The key was OK, but we cannot set the value losslessly\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/indexing.py:1785\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     indexer, missing \u001b[39m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[0;32m-> 1785\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_missing(indexer, value)\n\u001b[1;32m   1786\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mloc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1789\u001b[0m     \u001b[39m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/indexing.py:2135\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2131\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_values):\n\u001b[1;32m   2132\u001b[0m         \u001b[39m# GH#22717 handle casting compatibility that np.concatenate\u001b[39;00m\n\u001b[1;32m   2133\u001b[0m         \u001b[39m#  does incorrectly\u001b[39;00m\n\u001b[1;32m   2134\u001b[0m         new_values \u001b[39m=\u001b[39m concat_compat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_values, new_values])\n\u001b[0;32m-> 2135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor(\n\u001b[1;32m   2136\u001b[0m         new_values, index\u001b[39m=\u001b[39;49mnew_index, name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mname\n\u001b[1;32m   2137\u001b[0m     )\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m   2138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_maybe_update_cacher(clear\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2140\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/pandas/core/construction.py:526\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msanitize_array\u001b[39m(\n\u001b[1;32m    494\u001b[0m     data,\n\u001b[1;32m    495\u001b[0m     index: Index \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m     allow_2d: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    501\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[1;32m    502\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39m    Sanitize input data to an ndarray or ExtensionArray, copy if specified,\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39m    coerce to the dtype if specified.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m    applying to a subset of columns, see GH#24435.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(data, ma\u001b[39m.\u001b[39;49mMaskedArray):\n\u001b[1;32m    527\u001b[0m         data \u001b[39m=\u001b[39m sanitize_masked_array(data)\n\u001b[1;32m    529\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, PandasDtype):\n\u001b[1;32m    530\u001b[0m         \u001b[39m# Avoid ending up with a PandasArray\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = read_swf_file(file_path)\n",
    "\n",
    "# Смотрим только одну самую популярную очередь (one partition in Slurm)\n",
    "# Но какую очередь проверять для конкретного файла, надо смотреть по данным\n",
    "df = df[df['queue_id'] == 1] \n",
    "\n",
    "\n",
    "df.replace(-1, np.nan, inplace=True)\n",
    "df_with_features = extract_features(df)\n",
    "dataset = df_with_features[dataset_features]\n",
    "\n",
    "df_with_features.to_csv('../prepared_data/full_' + filename + '.csv')\n",
    "dataset.to_csv('../prepared_data/for_using_' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('../prepared_data/for_using_' + filename + '.csv')[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yashch/miniconda3/envs/torch/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56ca14e87e041f29fcb56a17f360539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 569.9961738\ttest: 844.0431485\tbest: 844.0431485 (0)\ttotal: 11ms\tremaining: 55.2s\n",
      "100:\tlearn: 567.1811916\ttest: 839.9722987\tbest: 839.9722987 (100)\ttotal: 994ms\tremaining: 48.2s\n",
      "200:\tlearn: 563.3283319\ttest: 834.6865106\tbest: 834.6865106 (200)\ttotal: 1.82s\tremaining: 43.6s\n",
      "300:\tlearn: 550.9246142\ttest: 816.1234684\tbest: 816.1234684 (300)\ttotal: 2.66s\tremaining: 41.5s\n",
      "400:\tlearn: 512.2836958\ttest: 751.1454350\tbest: 751.1454350 (400)\ttotal: 3.47s\tremaining: 39.8s\n",
      "500:\tlearn: 481.8500407\ttest: 699.2724857\tbest: 699.2724857 (500)\ttotal: 4.3s\tremaining: 38.7s\n",
      "600:\tlearn: 437.4904170\ttest: 624.8926707\tbest: 624.8926707 (600)\ttotal: 5.14s\tremaining: 37.6s\n",
      "700:\tlearn: 404.1685677\ttest: 570.5092295\tbest: 570.5092295 (700)\ttotal: 5.98s\tremaining: 36.7s\n",
      "800:\tlearn: 388.7886695\ttest: 543.9973672\tbest: 543.9973672 (800)\ttotal: 6.8s\tremaining: 35.6s\n",
      "900:\tlearn: 360.7006416\ttest: 499.2207554\tbest: 499.2207554 (900)\ttotal: 7.64s\tremaining: 34.8s\n",
      "1000:\tlearn: 344.8871656\ttest: 478.5373591\tbest: 478.5373591 (1000)\ttotal: 8.49s\tremaining: 33.9s\n",
      "1100:\tlearn: 325.0077056\ttest: 452.8453265\tbest: 452.8453265 (1100)\ttotal: 9.35s\tremaining: 33.1s\n",
      "1200:\tlearn: 315.3339717\ttest: 439.4889169\tbest: 439.4889169 (1200)\ttotal: 10.2s\tremaining: 32.3s\n",
      "1300:\tlearn: 308.0961539\ttest: 429.7056883\tbest: 429.7056883 (1300)\ttotal: 11.1s\tremaining: 31.5s\n",
      "1400:\tlearn: 291.9225837\ttest: 406.7277908\tbest: 406.7277908 (1400)\ttotal: 11.8s\tremaining: 30.2s\n",
      "1500:\tlearn: 280.2339048\ttest: 390.9514072\tbest: 390.9514072 (1500)\ttotal: 12.5s\tremaining: 29.1s\n",
      "1600:\tlearn: 266.0379125\ttest: 370.2091373\tbest: 370.2091373 (1600)\ttotal: 13.2s\tremaining: 28.1s\n",
      "1700:\tlearn: 254.0973203\ttest: 353.6895364\tbest: 353.6895364 (1700)\ttotal: 13.9s\tremaining: 26.9s\n",
      "1800:\tlearn: 239.1455521\ttest: 333.2272529\tbest: 333.2272529 (1800)\ttotal: 14.6s\tremaining: 25.9s\n",
      "1900:\tlearn: 216.6434001\ttest: 301.7318514\tbest: 301.7318514 (1900)\ttotal: 15.3s\tremaining: 25s\n",
      "2000:\tlearn: 197.5317273\ttest: 274.4438493\tbest: 274.4438493 (2000)\ttotal: 16s\tremaining: 23.9s\n",
      "2100:\tlearn: 176.5872807\ttest: 245.4538698\tbest: 245.4538698 (2100)\ttotal: 16.7s\tremaining: 23s\n",
      "2200:\tlearn: 165.6573905\ttest: 229.9188638\tbest: 229.9188638 (2200)\ttotal: 17.4s\tremaining: 22.2s\n",
      "2300:\tlearn: 157.6881195\ttest: 218.1897294\tbest: 218.1897294 (2300)\ttotal: 18.1s\tremaining: 21.2s\n",
      "2400:\tlearn: 153.7861563\ttest: 212.6894079\tbest: 212.6894064 (2399)\ttotal: 18.8s\tremaining: 20.3s\n",
      "2500:\tlearn: 145.2919157\ttest: 200.9625678\tbest: 200.9625678 (2500)\ttotal: 20s\tremaining: 20s\n",
      "2600:\tlearn: 138.7043969\ttest: 192.8896258\tbest: 192.8896258 (2600)\ttotal: 20.6s\tremaining: 19s\n",
      "2700:\tlearn: 134.7540747\ttest: 190.1372703\tbest: 190.1372703 (2700)\ttotal: 21.4s\tremaining: 18.2s\n",
      "2800:\tlearn: 133.9252666\ttest: 189.7304336\tbest: 189.7304336 (2800)\ttotal: 22.2s\tremaining: 17.4s\n",
      "2900:\tlearn: 133.8277223\ttest: 189.5923906\tbest: 189.5923906 (2900)\ttotal: 22.9s\tremaining: 16.6s\n",
      "3000:\tlearn: 133.7905558\ttest: 189.5263511\tbest: 189.5263511 (3000)\ttotal: 23.7s\tremaining: 15.8s\n",
      "3100:\tlearn: 133.7568953\ttest: 189.4683679\tbest: 189.4683679 (3100)\ttotal: 24.5s\tremaining: 15s\n",
      "3200:\tlearn: 133.7378730\ttest: 189.4387639\tbest: 189.4387639 (3200)\ttotal: 25.2s\tremaining: 14.2s\n",
      "3300:\tlearn: 133.7299295\ttest: 189.4255510\tbest: 189.4255510 (3300)\ttotal: 26.1s\tremaining: 13.4s\n",
      "3400:\tlearn: 133.7270265\ttest: 189.4211559\tbest: 189.4211559 (3400)\ttotal: 26.9s\tremaining: 12.7s\n",
      "3500:\tlearn: 133.7248020\ttest: 189.4187639\tbest: 189.4187639 (3500)\ttotal: 27.8s\tremaining: 11.9s\n",
      "3600:\tlearn: 133.7234577\ttest: 189.4173069\tbest: 189.4173069 (3600)\ttotal: 28.5s\tremaining: 11.1s\n",
      "3700:\tlearn: 133.7226390\ttest: 189.4164292\tbest: 189.4164292 (3700)\ttotal: 29.5s\tremaining: 10.4s\n",
      "3800:\tlearn: 133.7221378\ttest: 189.4159067\tbest: 189.4159067 (3800)\ttotal: 30.4s\tremaining: 9.59s\n",
      "3900:\tlearn: 133.7218476\ttest: 189.4156149\tbest: 189.4156149 (3900)\ttotal: 31.3s\tremaining: 8.81s\n",
      "4000:\tlearn: 133.7216745\ttest: 189.4154467\tbest: 189.4154467 (4000)\ttotal: 32s\tremaining: 7.99s\n",
      "4100:\tlearn: 133.7215666\ttest: 189.4153455\tbest: 189.4153455 (4100)\ttotal: 32.9s\tremaining: 7.21s\n",
      "4200:\tlearn: 133.7215057\ttest: 189.4152848\tbest: 189.4152848 (4200)\ttotal: 34.3s\tremaining: 6.52s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# X_train, X_test, y_train, y_test = \u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39m# Train the CatBoost model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model \u001b[39m=\u001b[39m CatBoostRegressor(iterations\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.005\u001b[39m, depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, loss_function\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set\u001b[39m=\u001b[39;49m(X_test, y_test), verbose\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, plot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/catboost/core.py:5590\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5588\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5591\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, column_description,\n\u001b[1;32m   5592\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5593\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/catboost/core.py:2278\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2274\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2276\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2277\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2278\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2279\u001b[0m         train_pool,\n\u001b[1;32m   2280\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2281\u001b[0m         params,\n\u001b[1;32m   2282\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2283\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2286\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/catboost/core.py:1705\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1705\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4585\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4634\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming feature_df is the DataFrame with all the extracted features\n",
    "X = feature_df.drop(columns=['wait_time'])  # Replace 'target_column' with the name of the column containing target values\n",
    "y = feature_df['wait_time']\n",
    "\n",
    "# Split the data without shuffling\n",
    "train_size = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = \n",
    "\n",
    "# Train the CatBoost model\n",
    "model = CatBoostRegressor(iterations=5000, learning_rate=0.005, depth=3, loss_function='MAE')\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=100, plot=True)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean squared error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17297281"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4159 * 4159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_time</th>\n",
       "      <th>req_procs</th>\n",
       "      <th>req_memory</th>\n",
       "      <th>req_time</th>\n",
       "      <th>active_jobs_count</th>\n",
       "      <th>total_used_procs</th>\n",
       "      <th>mean_used_procs</th>\n",
       "      <th>total_used_memory</th>\n",
       "      <th>mean_used_memory</th>\n",
       "      <th>queued_jobs_count</th>\n",
       "      <th>...</th>\n",
       "      <th>min_wait_time_completed</th>\n",
       "      <th>mean_run_time_completed</th>\n",
       "      <th>max_run_time_completed</th>\n",
       "      <th>min_run_time_completed</th>\n",
       "      <th>mean_procs_completed</th>\n",
       "      <th>max_procs_completed</th>\n",
       "      <th>min_procs_completed</th>\n",
       "      <th>mean_memory_completed</th>\n",
       "      <th>max_memory_completed</th>\n",
       "      <th>min_memory_completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44299</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>149.333333</td>\n",
       "      <td>57536.0</td>\n",
       "      <td>6392.888889</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715.495338</td>\n",
       "      <td>197453.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.291663</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4371.287509</td>\n",
       "      <td>29076.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_time  req_procs  req_memory  req_time  active_jobs_count  \\\n",
       "44299        2.0       64.0      4800.0    2700.0                9.0   \n",
       "\n",
       "       total_used_procs  mean_used_procs  total_used_memory  mean_used_memory  \\\n",
       "44299            1344.0       149.333333            57536.0       6392.888889   \n",
       "\n",
       "       queued_jobs_count  ...  min_wait_time_completed  \\\n",
       "44299               11.0  ...                      0.0   \n",
       "\n",
       "       mean_run_time_completed  max_run_time_completed  \\\n",
       "44299              2715.495338                197453.0   \n",
       "\n",
       "       min_run_time_completed  mean_procs_completed  max_procs_completed  \\\n",
       "44299                     0.0            104.291663               1024.0   \n",
       "\n",
       "       min_procs_completed  mean_memory_completed  max_memory_completed  \\\n",
       "44299                 32.0            4371.287509               29076.0   \n",
       "\n",
       "       min_memory_completed  \n",
       "44299                   0.0  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df[44299:44300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
